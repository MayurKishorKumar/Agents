{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database and table created successfully!\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Create the SQLite database\n",
    "conn = sqlite3.connect(\"sales.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create the sales table\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS sales (\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    product TEXT,\n",
    "    region TEXT,\n",
    "    sales INTEGER\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# Insert sample data\n",
    "sample_data = [\n",
    "    (\"Product X\", \"Region A\", 100),\n",
    "    (\"Product X\", \"Region B\", 200),\n",
    "    (\"Product Y\", \"Region A\", 150),\n",
    "    (\"Product Y\", \"Region B\", 300)\n",
    "]\n",
    "cursor.executemany(\"INSERT INTO sales (product, region, sales) VALUES (?, ?, ?)\", sample_data)\n",
    "\n",
    "# Commit changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"Database and table created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test PDF 'feedback.pdf' created successfully!\n"
     ]
    }
   ],
   "source": [
    "from fpdf import FPDF\n",
    "\n",
    "# Create a simple PDF\n",
    "pdf = FPDF()\n",
    "pdf.add_page()\n",
    "pdf.set_font(\"Arial\", size=12)\n",
    "pdf.cell(200, 10, txt=\"Customer Feedback\", ln=True, align=\"C\")\n",
    "pdf.ln(10)\n",
    "pdf.multi_cell(0, 10, txt=\"Region A: Customers reported durability issues.\\n\"\n",
    "                          \"Region B: Customers are satisfied with the product.\")\n",
    "pdf.output(\"feedback.pdf\")\n",
    "\n",
    "print(\"Test PDF 'feedback.pdf' created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Enhanced Multi-Hop Reasoning Agent \n",
      "\n",
      "Parsed Tasks: ['Analyze data']\n",
      "\n",
      "Analyze sales data\n",
      "\n",
      "Analyze customer feedback\n",
      "\n",
      "Analyze competitor data\n",
      "Insights: Competitor insights: Competitors in Region A offer durable products at competitive prices.\n",
      "\n",
      "Analyze market trends\n",
      "Insights: Market trends: Growing demand for sustainable and durable products in Region A.\n",
      "Insights: Sales data: [(1, 'Product X', 'Region A', 100), (2, 'Product X', 'Region B', 200)]\n",
      "Insights: Customer feedback: Customer Feedback\n",
      "Region A: Customers reported durability issues.\n",
      "Region B: Customers are satisfied with the product....\n",
      "\n",
      "Final Summary\n",
      "Sal√©, France - According to market research data, customer feedback reveals that in region A, consumers report issues with durability of the product. However, competitor insight suggests a trend towards growing demand for sustainable and durable products. The insight also highlights the changing demand patterns and increased consumer preferences for quality, reliability, and value-for-money products.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import sqlite3\n",
    "import spacy\n",
    "from PyPDF2 import PdfReader\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# The rest of the imports and classes remain the same until the SummarizationProcessor\n",
    "# Only showing the modified parts for clarity\n",
    "# === NLP-Based Query Parser === #\n",
    "class QueryParser:\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")  # Use SpaCy's local model\n",
    "\n",
    "    def parse(self, query):\n",
    "        doc = self.nlp(query)\n",
    "        tasks = [f\"Analyze {token.text.lower()}\" for token in doc if token.dep_ in (\"nsubj\", \"dobj\")]\n",
    "        return tasks\n",
    "\n",
    "# === Extended Data Retrieval === #\n",
    "class SQLDataSource:\n",
    "    def __init__(self, db_path, query):\n",
    "        self.db_path = db_path\n",
    "        self.query = query\n",
    "\n",
    "    def fetch_data(self):\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(self.query)\n",
    "        data = cursor.fetchall()\n",
    "        conn.close()\n",
    "        return {\"sql_data\": data}\n",
    "\n",
    "\n",
    "class DocumentParser:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "\n",
    "    def fetch_data(self):\n",
    "        if self.file_path.endswith(\".pdf\"):\n",
    "            text = self._parse_pdf()\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file format.\")\n",
    "        return {\"document_text\": text}\n",
    "\n",
    "    def _parse_pdf(self):\n",
    "        reader = PdfReader(self.file_path)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "\n",
    "\n",
    "class APIDataSource:\n",
    "    def __init__(self, api_url):\n",
    "        self.api_url = api_url\n",
    "\n",
    "    def fetch_data(self):\n",
    "        # Mock API responses\n",
    "        if \"competitors\" in self.api_url:\n",
    "            return {\"competitors\": \"Competitors in Region A offer durable products at competitive prices.\"}\n",
    "        elif \"market-trends\" in self.api_url:\n",
    "            return {\"market_trends\": \"Growing demand for sustainable and durable products in Region A.\"}\n",
    "        else:\n",
    "            raise ValueError(\"Invalid API URL\")\n",
    "\n",
    "\n",
    "# === Parallel Execution === #\n",
    "class ParallelReasoningPipeline:\n",
    "    def __init__(self):\n",
    "        self.steps = []\n",
    "\n",
    "    def add_step(self, description, data_source, processor):\n",
    "        self.steps.append({\"description\": description, \"data_source\": data_source, \"processor\": processor})\n",
    "\n",
    "    def run(self):\n",
    "        results = []\n",
    "\n",
    "        def process_step(step):\n",
    "            print(f\"\\n{step['description']}\")\n",
    "            data = step[\"data_source\"].fetch_data()\n",
    "            insights = step[\"processor\"].process(data)\n",
    "            print(f\"Insights: {insights}\")\n",
    "            return insights\n",
    "\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            futures = [executor.submit(process_step, step) for step in self.steps]\n",
    "            for future in futures:\n",
    "                results.append(future.result())\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "# === Enhanced Reasoning Logic === #\n",
    "class SalesProcessor:\n",
    "    def process(self, data):\n",
    "        return f\"Sales data: {data['sql_data']}\"\n",
    "\n",
    "\n",
    "class FeedbackProcessor:\n",
    "    def process(self, data):\n",
    "        return f\"Customer feedback: {data['document_text'][:200]}...\"  # Truncate for readability\n",
    "\n",
    "\n",
    "class CompetitorProcessor:\n",
    "    def process(self, data):\n",
    "        return f\"Competitor insights: {data['competitors']}\"\n",
    "\n",
    "\n",
    "class MarketTrendsProcessor:\n",
    "    def process(self, data):\n",
    "        return f\"Market trends: {data['market_trends']}\"\n",
    "\n",
    "class SummarizationProcessor:\n",
    "    \"\"\"\n",
    "    Summarizes insights using the Ollama API.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_name=\"tinyllama\"):\n",
    "        \"\"\"\n",
    "        Initialize the Ollama summarizer.\n",
    "        :param model_name: Name of the Ollama model to use (default: tinyllama).\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.api_url = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "    def process(self, insights):\n",
    "        \"\"\"\n",
    "        Summarizes the combined insights using the Ollama API.\n",
    "        :param insights: List of insights to summarize.\n",
    "        :return: Summarized text.\n",
    "        \"\"\"\n",
    "        combined_text = \" \".join(insights)\n",
    "        \n",
    "        # Prepare the prompt\n",
    "        prompt = f\"\"\"Please summarize the following insights concisely:\n",
    "\n",
    "{combined_text}\n",
    "\n",
    "Summary:\"\"\"\n",
    "\n",
    "        # Prepare the request payload\n",
    "        payload = {\n",
    "            \"model\": self.model_name,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": False\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            # Make request to Ollama API\n",
    "            response = requests.post(self.api_url, json=payload)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Extract the response\n",
    "            result = response.json()\n",
    "            return result.get('response', \"Unable to generate summary.\")\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            return f\"Error connecting to Ollama: {str(e)}\"\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Entry point for the program. Orchestrates query processing, reasoning steps, and summarization.\n",
    "    \"\"\"\n",
    "    print(\" Enhanced Multi-Hop Reasoning Agent \\n\")\n",
    "\n",
    "    # Initialize components\n",
    "    query = \"What are the key factors driving the decline in sales for Product X in the last quarter?\"\n",
    "    query_parser = QueryParser()\n",
    "    tasks = query_parser.parse(query)\n",
    "    print(f\"Parsed Tasks: {tasks}\")\n",
    "\n",
    "    # Initialize the pipeline\n",
    "    pipeline = ParallelReasoningPipeline()\n",
    "\n",
    "    # Add reasoning steps\n",
    "    pipeline.add_step(\n",
    "        \"Analyze sales data\",\n",
    "        SQLDataSource(\"sales.db\", \"SELECT * FROM sales WHERE product='Product X'\"),\n",
    "        SalesProcessor(),\n",
    "    )\n",
    "    pipeline.add_step(\n",
    "        \"Analyze customer feedback\",\n",
    "        DocumentParser(\"feedback.pdf\"),\n",
    "        FeedbackProcessor(),\n",
    "    )\n",
    "    pipeline.add_step(\n",
    "        \"Analyze competitor data\",\n",
    "        APIDataSource(\"mock://competitors\"),\n",
    "        CompetitorProcessor(),\n",
    "    )\n",
    "    pipeline.add_step(\n",
    "        \"Analyze market trends\",\n",
    "        APIDataSource(\"mock://market-trends\"),\n",
    "        MarketTrendsProcessor(),\n",
    "    )\n",
    "\n",
    "    # Run the pipeline\n",
    "    insights = pipeline.run()\n",
    "\n",
    "    # Summarize results using Ollama\n",
    "    summarizer = SummarizationProcessor(model_name=\"tinyllama\")  # You can change the model as needed\n",
    "    final_summary = summarizer.process(insights)\n",
    "\n",
    "    print(\"\\nFinal Summary\")\n",
    "    print(final_summary)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
